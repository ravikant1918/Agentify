# ðŸ¤– Agen## ðŸ§  Overview
**Agentify** is an open-source web application that lets you instantly create a functional AI chat assistant using your own **MCP tools**, **LLM provider**, and custom **system prompt**. It combines a modern web interface with powerful backend capabilities including LangChain ReAct agents for advanced reasoning.

With **zero coding**, developers can configure their preferred:
- ðŸ› ï¸ MCP tools and endpoints
- ðŸ¤– LLM provider (OpenAI, Azure, Anthropic, Groq, etc.)
- ðŸ’­ System instructions and behavior
- ðŸŽ¨ Web interface customization

> ðŸ’¡ *Think of it as your personal AI assistant builder â€” just configure your tools and models, then start chatting!*
**Turn config into a working agent.**

![License](https://img.shields.io/badge/License-MIT-blue.svg)
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Status](https://img.shields.io/badge/Status-Active-success)

---

## ðŸ§  Overview
**Agentify** is an open-source framework that lets you instantly create a functional problem-solving agent using your own **MCP URL**, **system prompt**, and **LLM configuration**.  

With **zero coding**, developers can simply clone the repo, fill in their config, and start solving problems right away.  

> ðŸ’¡ *Think of it as a plug-and-play agent builder â€” just configure, and youâ€™re ready to go.*

---

## âš™ï¸ Features
- ðŸŒ **Modern Web Interface** â€” Clean, responsive chat UI with real-time updates
- ðŸ”Œ **MCP Integration** â€” Connect to any MCP-compatible tool server
- ðŸ§  **Multi-LLM Support** â€” Works with OpenAI, Azure, Anthropic, Groq, and custom endpoints
- âš¡ **LangChain ReAct** â€” Advanced reasoning and autonomous tool usage
- ðŸ’¾ **Session Management** â€” Persistent chat history and context
- ðŸ› ï¸ **Docker Ready** â€” Easy deployment with Docker Compose
- ðŸ”§ **Customizable** â€” Simple configuration via UI or `.env`
- ðŸŽ¨ **Themeable UI** â€” Clean, modern design with customizable styles
- ðŸ“± **Responsive Design** â€” Works on desktop and mobile devices
- ðŸŒ **Open Source** â€” MIT licensed and free to use

---

## ðŸ“¦ Project Structure
```
.
â”œâ”€â”€ app.py                     # FastAPI web application entry point
â”œâ”€â”€ deploy.sh                  # Deployment automation script
â”œâ”€â”€ docker-compose.yml         # Docker container orchestration
â”œâ”€â”€ Dockerfile                 # Docker image configuration
â”œâ”€â”€ langchain_react_agent.py   # LangChain ReAct agent implementation
â”œâ”€â”€ main.py                    # Main MCP client application
â”œâ”€â”€ requirement.txt            # Project dependencies
â”œâ”€â”€ run_agent.py              # Agent execution script
â”œâ”€â”€ src/                      # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py             # Agent implementation
â”‚   â”œâ”€â”€ config_manager.py    # Secure configuration management
â”‚   â”œâ”€â”€ llm_factory.py       # LLM provider configuration
â”‚   â”œâ”€â”€ mcp_client.py        # MCP integration client
â”‚   â””â”€â”€ session_manager.py   # Session management
â”œâ”€â”€ static/                   # Static web assets
â”‚   â””â”€â”€ styles.css           # UI styling
â””â”€â”€ templates/               # HTML templates
    â”œâ”€â”€ config.html         # Configuration management UI
    â””â”€â”€ index.html         # Main chat interface
```
.
â”œâ”€â”€ app.py                     # FastAPI web application entry point
â”œâ”€â”€ deploy.sh                  # Deployment automation script
â”œâ”€â”€ docker-compose.yml         # Docker container orchestration
â”œâ”€â”€ Dockerfile                 # Docker image configuration
â”œâ”€â”€ langchain_react_agent.py   # LangChain ReAct agent implementation
â”œâ”€â”€ main.py                    # Main MCP client application
â”œâ”€â”€ requirement.txt            # Project dependencies
â”œâ”€â”€ run_agent.py              # Agent execution script
â”œâ”€â”€ src/                      # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py             # Agent implementation
â”‚   â”œâ”€â”€ llm_factory.py       # LLM provider configuration
â”‚   â”œâ”€â”€ mcp_client.py        # MCP integration client
â”‚   â””â”€â”€ session_manager.py   # Session management
â”œâ”€â”€ static/                   # Static web assets
â”‚   â””â”€â”€ styles.css           # UI styling
â””â”€â”€ templates/               # HTML templates
    â””â”€â”€ index.html          # Main chat interface
```

---

## ðŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/agentify.git
cd agentify
```

### 2ï¸âƒ£ Set Up Environment
Copy the example environment file:
```bash
cp .env.example .env
```

Edit the `.env` file and fill in your configuration:

```bash
MCP_URL=https://your-mcp-url.com
SYSTEM_PROMPT="You are a helpful AI assistant that solves user queries."
LLM_API_KEY=your-api-key-here
MODEL_NAME=gpt-4o
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Quickstart Example
```bash
python examples/quickstart.py
```

âœ… Your agent is now live and ready to solve problems!

---

## ðŸ§© Example Usage
```python
from agentify.agent_runner import AgentRunner

agent = AgentRunner()
response = agent.solve("How do I optimize my Python code?")
print(response)
```

---

## ðŸ”§ Configuration Management

### Web Interface
Agentify now includes a comprehensive configuration management UI accessible at `/config`. Here you can:

- ðŸ”„ **Manage Multiple MCP Servers**
  - Add, edit, and remove MCP server configurations
  - Set server URLs, authentication, and custom settings
  - Switch between different MCP servers in real-time

- ðŸ”‘ **LLM Settings**
  - Configure multiple LLM providers (OpenAI, Azure, etc.)
  - Securely store API keys and endpoints
  - Set model preferences and parameters

- ðŸ’¾ **Persistent Storage**
  - All configurations are securely stored in Redis
  - Sensitive data is encrypted at rest
  - Easy backup and restore functionality

### Environment Variables

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `REDIS_URL` | Redis connection URL for config storage | `redis://localhost:6379` | Yes |
| `ENCRYPTION_KEY` | Key for securing sensitive data | - | Yes |
| `DEFAULT_MCP_URL` | Default MCP server URL | `http://localhost:8000` | No |
| `DEFAULT_LLM_PROVIDER` | Default LLM provider | `azure` | No |
| `LLM_API_KEY` | Default API key for LLM | - | Yes |
| `AZURE_ENDPOINT` | Azure OpenAI endpoint (if using Azure) | - | No |
| `MODEL_NAME` | Default model to use | `gpt-4` | No |

### Redis Setup

1. Install Redis:
   ```bash
   # macOS with Homebrew
   brew install redis
   brew services start redis

   # Ubuntu/Debian
   sudo apt-get install redis-server
   sudo systemctl start redis-server
   ```

2. Set the encryption key:
   ```bash
   export ENCRYPTION_KEY=$(openssl rand -hex 32)
   ```

3. Verify Redis connection:
   ```bash
   redis-cli ping
   ```

### Configuration API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/mcp/servers` | GET | List all MCP servers |
| `/api/mcp/servers` | POST | Add new MCP server |
| `/api/mcp/servers/{id}` | DELETE | Remove MCP server |
| `/api/mcp/servers/{id}` | PATCH | Update MCP server |
| `/api/llm/config` | POST | Update LLM settings |

### Configuration File Example
```json
{
  "mcp_servers": [
    {
      "id": "dev-server",
      "url": "http://localhost:8000",
      "auth_type": "none"
    },
    {
      "id": "prod-server",
      "url": "https://mcp.example.com",
      "auth_type": "bearer",
      "auth_token": "xxx"
    }
  ],
  "llm_config": {
    "provider": "azure",
    "model": "gpt-4",
    "api_version": "2024-12-01-preview",
    "azure_endpoint": "https://your-endpoint.openai.azure.com"
  }
}

---

## ðŸ“š Folder Details
- `agentify/core.py` â†’ Core logic for agent workflow  
- `agentify/config_loader.py` â†’ Loads environment/config variables  
- `agentify/agent_runner.py` â†’ Executes the agent using loaded config  
- `examples/quickstart.py` â†’ Demo entry point for testing your setup  

---

## ðŸ¤ Contributing
Contributions are welcome!  
If youâ€™d like to improve **Agentify**, fork the repo and submit a pull request.

1. Fork the repository  
2. Create your feature branch (`git checkout -b feature-name`)  
3. Commit your changes (`git commit -m 'Add new feature'`)  
4. Push to your branch (`git push origin feature-name`)  
5. Open a Pull Request  

---

## ðŸ§¾ License
This project is licensed under the [MIT License](LICENSE).  
Youâ€™re free to use, modify, and distribute it â€” just keep the license file.

---

## â¤ï¸ Support
If you find **Agentify** useful, please â­ star the repo and share it with others.  
For issues or feature requests, open a [GitHub Issue](https://github.com/your-username/agentify/issues).

---

> **Agentify â€” Turn config into a working agent.**
> Clone. Configure. Create.

